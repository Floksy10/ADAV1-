% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  12pt,
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
  \setmainfont[]{Arial}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Model accuracy and fit},
  colorlinks=true,
  linkcolor={Maroon},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={blue},
  pdfcreator={LaTeX via pandoc}}

\title{Model accuracy and fit}
\author{}
\date{\vspace{-2.5em}}

\begin{document}
\maketitle

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{1}
\tableofcontents
}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

In this lab, you will learn how to plot a linear regression with
confidence and prediction intervals, and various tools to assess model
fit: calculating the MSE, making train-test splits, and writing a
function for cross validation. You can download the student zip
including all needed files for practical 3
\href{https://surfdrive.surf.nl/files/index.php/s/BcQtVPSdH7bCYZA}{here}.

Note: the completed homework (the whole practical) has to be
\textbf{handed in} on Black Board and will be \textbf{graded}
(pass/fail, counting towards your grade for the individual assignment).
\textbf{The deadline Monday 13th of May, end of day}. Hand-in should be
a \textbf{PDF} file. If you know how to knit pdf files, you can hand in
the knitted pdf file. However, if you have not done this before, you are
advised to knit to a html file as specified below, and within the html
browser, `print' your file as a pdf file.

Please note that not all questions are dependent to each other; if you
do not know the answer of one question, you can still solve part of the
remaining lab.

We will use the \texttt{Boston} dataset, which is in the \texttt{MASS}
package that comes with \texttt{R}. In addition, we will make use of the
\texttt{caret} package to divide the \texttt{Boston} dataset into a
training, test, and validation set.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ISLR)}
\FunctionTok{library}\NormalTok{(MASS)}
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(caret)}
\end{Highlighting}
\end{Shaded}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

As always, the first thing we want to do is to inspect the Boston
dataset using the \texttt{View()} function:

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{view}\NormalTok{(Boston)}
\end{Highlighting}
\end{Shaded}

The \texttt{Boston} dataset contains the housing values and other
information about Boston suburbs. We will use the dataset to predict
housing value (the variable \texttt{medv} - Median value of
owner-occupied homes in \$1000's - is the outcome/dependent variable) by
socio-economic status (the variable \texttt{lstat} - \% lower status of
the population - is the predictor / independent variable).

Let's explore socio-economic status and housing value in the dataset
using visualization. Use the following code to create a scatter plot
from the \texttt{Boston} dataset with \texttt{lstat} mapped to the x
position and \texttt{medv} mapped to the y position. We can store the
plot in an object called \texttt{p\_scatter}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p\_scatter }\OtherTok{\textless{}{-}} 
\NormalTok{  Boston }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ lstat, }\AttributeTok{y =}\NormalTok{ medv)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}

\NormalTok{p\_scatter}
\end{Highlighting}
\end{Shaded}

\includegraphics{R_model_accuracy_stu_files/figure-latex/sctr-1.pdf}

In the scatter plot, we can see that that the median value of
owner-occupied homes in \$1000's (medv) is going down as the percentage
of the lower status of the population (lstat) increases.

\hypertarget{plotting-observed-data-including-a-prediction-line}{%
\section{Plotting observed data including a prediction
line}\label{plotting-observed-data-including-a-prediction-line}}

We'll start with making and visualizing the linear model. As you know, a
linear model is fitted in \texttt{R} using the function \texttt{lm()},
which then returns a \texttt{lm} object. We are going to walk through
the construction of a plot with a fit line. Then we will add confidence
intervals from an \texttt{lm} object to this plot.

First, we will create the linear model. This model will be used to
predict outcomes for the current data set, and - further along in this
lab - to create new data to enable adding the prediction line to the
scatter plot.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Use the following code to create a linear model object called
  \texttt{lm\_ses} using the formula
  \texttt{medv\ \textasciitilde{}\ lstat} and the \texttt{Boston}
  dataset.}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm\_ses }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lstat, }\AttributeTok{data =}\NormalTok{ Boston)}
\end{Highlighting}
\end{Shaded}

You have now trained a regression model with \texttt{medv} (housing
value) as the outcome/dependent variable and \texttt{lstat}
(socio-economic status) as the predictor / independent variable.

Remember that a regression estimates \(\beta_0\) (the intercept) and
\(\beta_1\) (the slope) in the following equation:

\[\boldsymbol{y} = \beta_0 + \beta_1\cdot \boldsymbol{x}_1 + \boldsymbol{\epsilon}\]

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Use the function \texttt{coef()} to extract the intercept and
  slope from the \texttt{lm\_ses} object. Interpret the slope
  coefficient.}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coefficients }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(lm\_ses)}
\NormalTok{intercept }\OtherTok{\textless{}{-}}\NormalTok{ coefficients[}\DecValTok{1}\NormalTok{]}
\NormalTok{slope }\OtherTok{\textless{}{-}}\NormalTok{ coefficients[}\DecValTok{2}\NormalTok{]}

\FunctionTok{print}\NormalTok{(intercept)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept) 
##    34.55384
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(slope)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      lstat 
## -0.9500494
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#The slope coefficient (β1) = {-}0.9500494 represents the change in the median value of homes for each one{-}unit increase in the percentage of lower status population. A negative slope would indicate that as the lstat increases, the medv tends to decrease, suggesting that higher socio{-}economic challenges are associated with lower housing values.}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Use \texttt{summary()} to get a summary of the
  \texttt{lm\_ses} object. What do you see? You can use the help file
  \texttt{?summary.lm}.}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_summary }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(lm\_ses)}

\FunctionTok{print}\NormalTok{(model\_summary)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = medv ~ lstat, data = Boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.168  -3.990  -1.318   2.034  24.500 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 34.55384    0.56263   61.41   <2e-16 ***
## lstat       -0.95005    0.03873  -24.53   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.216 on 504 degrees of freedom
## Multiple R-squared:  0.5441, Adjusted R-squared:  0.5432 
## F-statistic: 601.6 on 1 and 504 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#The output from summary(lm\_ses) that will help us understand the strength and significance of the relationship between medv and lstat, and how well the model fits the data.}
\end{Highlighting}
\end{Shaded}

We now have a model object \texttt{lm\_ses} that represents the formula

\[\text{medv}_i = 34.55 - 0.95 * \text{lstat}_i + \epsilon_i\]

With this object, we can predict a new \texttt{medv} value by inputting
its \texttt{lstat} value. The \texttt{predict()} method enables us to do
this for the \texttt{lstat} values in the original dataset.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \textbf{Save the predicted y values to a variable called
  \texttt{y\_pred}. Use the \texttt{predict} function}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(lm\_ses)}
\end{Highlighting}
\end{Shaded}

To generate a nice, smooth prediction line, we need a large range of
(equally spaced) hypothetical \texttt{lstat} values. Next, we can use
these hypothetical \texttt{lstat} values to generate predicted housing
values with \texttt{predict()} method using the \texttt{newdat}
argument.

One method to generate these hypothetical values is through using the
function \texttt{seq()}. This function from \texttt{base\ R} generates a
sequence of number using a standardized method. Typically length of the
requested sequence divided by the range between \texttt{from} to
\texttt{to}. For more information call \texttt{?seq}.

Use the following code and the \texttt{seq()} function to generate a
sequence of 1000 equally spaced values from 0 to 40. We will store this
vector in a data frame with (\texttt{data.frame()} or \texttt{tibble()})
as its column name \texttt{lstat}. We will name the data frame
\texttt{pred\_dat}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred\_dat }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{lstat =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{40}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{1000}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Now we will use the newly created data frame as the \texttt{newdata}
argument to a \texttt{predict()} call for \texttt{lm\_ses} and we will
store it in a variable named \texttt{y\_pred\_new}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred\_new }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(lm\_ses, }\AttributeTok{newdata =}\NormalTok{ pred\_dat)}
\end{Highlighting}
\end{Shaded}

Now, we'll continue with the plotting part by adding a prediction line
to the plot we previously constructed.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Use the following code to add the vector \texttt{y\_pred\_new} to the
\texttt{pred\_dat} data frame with the name \texttt{medv}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# this can be done in several ways. Here are two possibilities:}
\CommentTok{\# pred\_dat$medv \textless{}{-} y\_pred\_new}
\NormalTok{pred\_dat }\OtherTok{\textless{}{-}}\NormalTok{ pred\_dat }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{medv =}\NormalTok{ y\_pred\_new)}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Finally, we will add a geom\_line() to \texttt{p\_scatter}, with
\texttt{pred\_dat} as the \texttt{data} argument. What does this line
represent?

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p\_scatter }\SpecialCharTok{+} \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ pred\_dat)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R_model_accuracy_stu_files/figure-latex/line-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# This line represents predicted values of medv for the values of lstat }
\end{Highlighting}
\end{Shaded}

\hypertarget{plotting-linear-regression-with-confindence-intervals}{%
\section{Plotting linear regression with confindence
intervals}\label{plotting-linear-regression-with-confindence-intervals}}

We will continue with the \texttt{Boston} dataset, the created model
\texttt{lm\_ses} that predicts \texttt{medv} (housing value) by
\texttt{lstat} (socio-economic status), and the predicted housing values
stored in \texttt{y\_pred}. Now, we will - step by step - add confidence
intervals to our plotted prediction line.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  \textbf{The \texttt{interval} argument can be used to generate
  confidence or prediction intervals. Create a new object called
  \texttt{y\_conf\_95} using \texttt{predict()} (again with the
  \texttt{pred\_dat} data) with the \texttt{interval} argument set to
  ``confidence''. What is in this object?}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_conf\_95 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(lm\_ses, }\AttributeTok{newdata =}\NormalTok{ pred\_dat, }\AttributeTok{interval =} \StringTok{"confidence"}\NormalTok{)}

\FunctionTok{head}\NormalTok{(y\_conf\_95)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        fit      lwr      upr
## 1 34.55384 33.44846 35.65922
## 2 34.51580 33.41307 35.61853
## 3 34.47776 33.37768 35.57784
## 4 34.43972 33.34229 35.53715
## 5 34.40168 33.30690 35.49646
## 6 34.36364 33.27150 35.45578
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#The fitted values (predicted values of medv for each observation in the dataset).}

\CommentTok{\#The lower and upper bounds of the 95\% confidence intervals for these predictions.}
\CommentTok{\#This gives an estimate of where the true mean response is expected to lie with 95\% confidence.}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  \textbf{Using the data from Question 5 (\texttt{y\_conf\_95}), and the
  sequence created earlier; create a data frame with 4 columns:
  \texttt{medv}, \texttt{lstat}, \texttt{lower}, and \texttt{upper}. For
  the \texttt{lstat} use the \texttt{pred\_dat\$lstat}; for
  \texttt{medv}, \texttt{lower}, and \texttt{upper} use data from
  \texttt{y\_conf\_95}}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{lstat =}\NormalTok{ pred\_dat}\SpecialCharTok{$}\NormalTok{lstat,                  }\CommentTok{\# Use lstat from the Boston dataset}
  \AttributeTok{medv =}\NormalTok{ y\_conf\_95[, }\StringTok{"fit"}\NormalTok{],            }\CommentTok{\# Predicted medv values from y\_conf\_95}
  \AttributeTok{lower =}\NormalTok{ y\_conf\_95[, }\StringTok{"lwr"}\NormalTok{],           }\CommentTok{\# Lower bound of the confidence interval}
  \AttributeTok{upper =}\NormalTok{ y\_conf\_95[, }\StringTok{"upr"}\NormalTok{]              }\CommentTok{\# Upper bound of the confidence interval}
\NormalTok{)}


\FunctionTok{head}\NormalTok{(results\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        lstat     medv    lower    upper
## 1 0.00000000 34.55384 33.44846 35.65922
## 2 0.04004004 34.51580 33.41307 35.61853
## 3 0.08008008 34.47776 33.37768 35.57784
## 4 0.12012012 34.43972 33.34229 35.53715
## 5 0.16016016 34.40168 33.30690 35.49646
## 6 0.20020020 34.36364 33.27150 35.45578
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  \textbf{Add a \texttt{geom\_ribbon()} to the plot with the data frame
  you just made. The ribbon geom requires three aesthetics: \texttt{x}
  (\texttt{lstat}, already mapped), \texttt{ymin} (\texttt{lower}), and
  \texttt{ymax} (\texttt{upper}). Add the ribbon below the
  \texttt{geom\_line()} and the \texttt{geom\_points()} of before to
  make sure those remain visible. Give it a nice colour and clean up the
  plot, too!}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(gridExtra)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Attaching package: 'gridExtra'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:dplyr':
## 
##     combine
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(dplyr)}

\CommentTok{\# Assuming results\_df is derived correctly and includes all necessary columns}
\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ results\_df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ lstat, }\AttributeTok{y =}\NormalTok{ medv)) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ lower, }\AttributeTok{ymax =}\NormalTok{ upper), }\AttributeTok{fill =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}  \CommentTok{\# Add geom\_ribbon for confidence intervals}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{color =} \StringTok{"darkblue"}\NormalTok{) }\SpecialCharTok{+}  \CommentTok{\# Add the line for the predictions}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ medv), }\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}  \CommentTok{\# Add actual data points using the same medv from results\_df}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"Relationship between LSTAT and MEDV with Confidence Intervals"}\NormalTok{,}
    \AttributeTok{x =} \StringTok{"LSTAT (\% lower status of the population)"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"MEDV (Median value of owner{-}occupied homes in $1000s)"}\NormalTok{,}
    \AttributeTok{caption =} \StringTok{"Data from Boston dataset"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}  \CommentTok{\# Use a minimal theme}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{),  }\CommentTok{\# Center the plot title}
    \AttributeTok{legend.position =} \StringTok{"none"}  \CommentTok{\# Hide the legend, as it\textquotesingle{}s clear from the context}
\NormalTok{  )}

\CommentTok{\# Print the plot}
\FunctionTok{print}\NormalTok{(p)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R_model_accuracy_stu_files/figure-latex/plot-1.pdf}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  \textbf{Explain in your own words what the ribbon represents.}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Confidence Intervals: This shaded ribbon shows where we expect the actual values to lie, with a certain level of confidence, usually 95\%. It means we are 95\% sure that the true values are within this ribbon.}

\CommentTok{\#Width of the Ribbon: Where the ribbon is wider, our predictions are less certain, and where it’s narrower, our predictions are more confident.}

\CommentTok{\#Understanding Uncertainty: The ribbon helps us see how sure we can be about the predictions at different levels of lstat, the socio{-}economic status indicator. If the ribbon is broad at certain points, it means there’s more uncertainty in predicting house values at those points.}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\tightlist
\item
  \textbf{Do the same thing, but now with the prediction interval
  instead of the confidence interval.}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred\_int }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(lm\_ses, }\AttributeTok{newdata =}\NormalTok{ Boston, }\AttributeTok{interval =} \StringTok{"prediction"}\NormalTok{)}


\NormalTok{pred\_results\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{lstat =}\NormalTok{ Boston}\SpecialCharTok{$}\NormalTok{lstat,                   }\CommentTok{\# Predictor}
  \AttributeTok{medv =}\NormalTok{ y\_pred\_int[, }\StringTok{"fit"}\NormalTok{],             }\CommentTok{\# Predicted values}
  \AttributeTok{lower =}\NormalTok{ y\_pred\_int[, }\StringTok{"lwr"}\NormalTok{],            }\CommentTok{\# Lower bound of the prediction interval}
  \AttributeTok{upper =}\NormalTok{ y\_pred\_int[, }\StringTok{"upr"}\NormalTok{]             }\CommentTok{\# Upper bound of the prediction interval}
\NormalTok{)}


\NormalTok{p\_pred }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(pred\_results\_df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ lstat, }\AttributeTok{y =}\NormalTok{ medv)) }\SpecialCharTok{+}
  \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ lower, }\AttributeTok{ymax =}\NormalTok{ upper), }\AttributeTok{fill =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}  \CommentTok{\# Add geom\_ribbon for prediction intervals}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{color =} \StringTok{"darkblue"}\NormalTok{) }\SpecialCharTok{+}  \CommentTok{\# Add the line for the predictions}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ Boston}\SpecialCharTok{$}\NormalTok{medv), }\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}  \CommentTok{\# Add actual data points}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"Relationship between LSTAT and MEDV with Prediction Intervals"}\NormalTok{,}
    \AttributeTok{x =} \StringTok{"LSTAT (\% lower status of the population)"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"MEDV (Median value of owner{-}occupied homes in $1000s)"}\NormalTok{,}
    \AttributeTok{caption =} \StringTok{"Data from Boston dataset"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}  \CommentTok{\# Use a minimal theme}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{),  }\CommentTok{\# Center the plot title}
    \AttributeTok{legend.position =} \StringTok{"none"}  \CommentTok{\# Hide the legend}
\NormalTok{  )}

\CommentTok{\# Print the plot}
\FunctionTok{print}\NormalTok{(p\_pred)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R_model_accuracy_stu_files/figure-latex/predint-1.pdf}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{model-fit-using-the-mean-square-error}{%
\section{Model fit using the mean square
error}\label{model-fit-using-the-mean-square-error}}

Next, we will write a function to assess the model fit using the mean
square error: the square of how much our predictions on average differ
from the observed values. Functions are ``self contained'' modules of
code that accomplish a specific task. Functions usually ``take in''
data, process it, and ``return'' a result. If you are not familiar with
functions, please read more on chapter 19 of the book ``R for Data
Science'' \href{https://r4ds.had.co.nz/functions.html}{here}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{9}
\tightlist
\item
  \textbf{Write a function called \texttt{mse()} that takes in two
  vectors: true y values and predicted y values, and which outputs the
  mean square error.}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Start like so:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mse }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(y\_true, y\_pred) \{}
  \CommentTok{\# your formula here}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\href{https://en.wikipedia.org/w/index.php?title=Mean_squared_error\&oldid=857685443}{Wikipedia}
may help for the formula.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mse }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(y\_true, y\_pred) \{}
  \CommentTok{\# Calculate the differences between actual and predicted values}
\NormalTok{  residuals }\OtherTok{\textless{}{-}}\NormalTok{ y\_true }\SpecialCharTok{{-}}\NormalTok{ y\_pred}
  
  \CommentTok{\# Square the residuals}
\NormalTok{  squared\_residuals }\OtherTok{\textless{}{-}}\NormalTok{ residuals}\SpecialCharTok{\^{}}\DecValTok{2}
  
  \CommentTok{\# Calculate the mean of the squared residuals}
\NormalTok{  mean\_squared\_error }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(squared\_residuals)}
  
  \CommentTok{\# Return the mean squared error}
  \FunctionTok{return}\NormalTok{(mean\_squared\_error)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Make sure your \texttt{mse()} function works correctly by running the
following code.\_\_

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#remove the comment to run the function}
\FunctionTok{mse}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, }\DecValTok{10}\SpecialCharTok{:}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 33
\end{verbatim}

In the code, we state that our observed values correspond to
\(1, 2, ..., 9, 10\), while our predicted values correspond to
\(10, 9, ..., 2, 1\). This is graphed below, where the blue dots
correspond to the observed values, and the yellow dots correspond to the
predicted values. Using your function, you have now calculated the mean
squared length of the dashed lines depicted in the graph below.

If your function works correctly, the value returned should equal 33.

\includegraphics{R_model_accuracy_stu_files/figure-latex/mseplot-1.pdf}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{10}
\tightlist
\item
  \textbf{Calculate the mean square error of the \texttt{lm\_ses} model.
  Use the \texttt{medv} column as \texttt{y\_true} and use the
  \texttt{predict()} method to generate \texttt{y\_pred}.}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(lm\_ses, }\AttributeTok{newdata =}\NormalTok{ Boston)}


\NormalTok{y\_true }\OtherTok{\textless{}{-}}\NormalTok{ Boston}\SpecialCharTok{$}\NormalTok{medv}


\NormalTok{model\_mse }\OtherTok{\textless{}{-}} \FunctionTok{mse}\NormalTok{(y\_true, y\_pred)}


\FunctionTok{print}\NormalTok{(model\_mse)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 38.48297
\end{verbatim}

You have calculated the mean squared length of the dashed lines in the
plot below. As the MSE is computed using the data that was used to fit
the model, we actually obtained the training MSE.

Below we continue with splitting our data in a training, test and
validation set such that we can calculate the out-of sample prediction
error during model building using the validation set, and estimate the
true out-of-sample MSE using the test set.

\begin{verbatim}
## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
## i Please use `linewidth` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
## generated.
\end{verbatim}

\includegraphics{R_model_accuracy_stu_files/figure-latex/mseplot2-1.pdf}

Note that you can also easily obtain how much the predictions on average
differ from the observed values in the original scale of the outcome
variable. To obtain this, you take the root of the mean square error.
This is called the Root Mean Square Error, abbreviated as RMSE.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{train-validation-test-splits}{%
\section{Train-validation-test
splits}\label{train-validation-test-splits}}

Next, we will use the \texttt{caret} package and the function
\texttt{createDataPartition()} to obtain a training, test, and
validation set from the \texttt{Boston} dataset. For more information on
this package, see the
\href{https://topepo.github.io/caret/index.html}{caret website}. The
training set will be used to fit our model, the validation set will be
used to calculate the out-of sample prediction error during model
building, and the test set will be used to estimate the true
out-of-sample MSE.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Use the code given below to obtain training, test, and validation set
from the \texttt{Boston} dataset.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\CommentTok{\# define the training partition }
\NormalTok{train\_index }\OtherTok{\textless{}{-}} \FunctionTok{createDataPartition}\NormalTok{(Boston}\SpecialCharTok{$}\NormalTok{medv, }\AttributeTok{p =}\NormalTok{ .}\DecValTok{7}\NormalTok{, }
                                  \AttributeTok{list =} \ConstantTok{FALSE}\NormalTok{, }
                                  \AttributeTok{times =} \DecValTok{1}\NormalTok{)}

\CommentTok{\# split the data using the training partition to obtain training data}
\NormalTok{boston\_train }\OtherTok{\textless{}{-}}\NormalTok{ Boston[train\_index,]}

\CommentTok{\# remainder of the split is the validation and test data (still) combined }
\NormalTok{boston\_val\_and\_test }\OtherTok{\textless{}{-}}\NormalTok{ Boston[}\SpecialCharTok{{-}}\NormalTok{train\_index,]}

\CommentTok{\# split the remaining 30\% of the data in a validation and test set}
\NormalTok{val\_index }\OtherTok{\textless{}{-}} \FunctionTok{createDataPartition}\NormalTok{(boston\_val\_and\_test}\SpecialCharTok{$}\NormalTok{medv, }\AttributeTok{p =}\NormalTok{ .}\DecValTok{66}\NormalTok{, }
                                  \AttributeTok{list =} \ConstantTok{FALSE}\NormalTok{, }
                                  \AttributeTok{times =} \DecValTok{1}\NormalTok{)}

\NormalTok{boston\_valid }\OtherTok{\textless{}{-}}\NormalTok{ boston\_val\_and\_test[val\_index,]}
\NormalTok{boston\_test  }\OtherTok{\textless{}{-}}\NormalTok{ boston\_val\_and\_test[}\SpecialCharTok{{-}}\NormalTok{val\_index,]}


\CommentTok{\# Outcome of this section is that the data (100\%) is split into:}
\CommentTok{\# training (\textasciitilde{}70\%)}
\CommentTok{\# validation (\textasciitilde{}20\%)}
\CommentTok{\# test (\textasciitilde{}10\%)}
\end{Highlighting}
\end{Shaded}

Note that creating the partitions using the \texttt{y} argument (letting
the function know what your dependent variable will be in the analysis),
makes sure that when your dependent variable is a factor, the random
sampling occurs within each class and should preserve the overall class
distribution of the data.

We will set aside the \texttt{boston\_test} dataset for now.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{11}
\tightlist
\item
  \textbf{Train a linear regression model called \texttt{model\_1} using
  the training dataset. Use the formula
  \texttt{medv\ \textasciitilde{}\ lstat} like in the first
  \texttt{lm()} exercise. Use \texttt{summary()} to check that this
  object is as you expect.}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lstat, }\AttributeTok{data =}\NormalTok{ boston\_train)}

\FunctionTok{summary}\NormalTok{(model\_1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = medv ~ lstat, data = boston_train)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.204  -4.001  -1.554   2.139  24.448 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 34.51510    0.69057   49.98   <2e-16 ***
## lstat       -0.94050    0.04705  -19.99   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.385 on 354 degrees of freedom
## Multiple R-squared:  0.5302, Adjusted R-squared:  0.5289 
## F-statistic: 399.5 on 1 and 354 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#lm(medv \textasciitilde{} lstat, data = boston\_train): This line creates a linear regression model where medv (median value of owner{-}occupied homes) is predicted from lstat (percentage of lower status of the population). The model is trained using the boston\_train dataset, which is assumed to be a subset of the Boston data prepared for training purposes.}

\CommentTok{\#summary(model\_1): This function call will print a summary of the linear model, providing detailed information about the coefficients (including estimates and significance), the overall fit of the model (R{-}squared, F{-}statistic), and other diagnostic measures. The summary helps in evaluating how well lstat predicts medv and whether the relationship is statistically significant.}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{12}
\tightlist
\item
  \textbf{Calculate the MSE with this object. Save this value as
  \texttt{model\_1\_mse\_train}.}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred\_train }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(model\_1, }\AttributeTok{newdata =}\NormalTok{ boston\_train)}

\CommentTok{\# Actual values from the training dataset}
\NormalTok{y\_true\_train }\OtherTok{\textless{}{-}}\NormalTok{ boston\_train}\SpecialCharTok{$}\NormalTok{medv}

\CommentTok{\# Calculate the Mean Square Error using the mse function}
\NormalTok{model\_1\_mse\_train }\OtherTok{\textless{}{-}} \FunctionTok{mse}\NormalTok{(y\_true\_train, y\_pred\_train)}

\CommentTok{\# Save this value}
\FunctionTok{print}\NormalTok{(model\_1\_mse\_train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 40.535
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{13}
\tightlist
\item
  \textbf{Now calculate the MSE on the validation set and assign it to
  variable \texttt{model\_1\_mse\_valid}. Hint: use the \texttt{newdata}
  argument in \texttt{predict()}.}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Generate predicted values using the trained model on the validation dataset}
\NormalTok{y\_pred\_valid }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(model\_1, }\AttributeTok{newdata =}\NormalTok{ boston\_test)}

\CommentTok{\# Actual values from the validation dataset}
\NormalTok{y\_true\_valid }\OtherTok{\textless{}{-}}\NormalTok{ boston\_test}\SpecialCharTok{$}\NormalTok{medv}

\CommentTok{\# Calculate the Mean Square Error using the mse function for the validation data}
\NormalTok{model\_1\_mse\_valid }\OtherTok{\textless{}{-}} \FunctionTok{mse}\NormalTok{(y\_true\_valid, y\_pred\_valid)}

\CommentTok{\# Save this value}
\FunctionTok{print}\NormalTok{(model\_1\_mse\_valid)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 35.62423
\end{verbatim}

This is the estimated out-of-sample mean squared error.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{14}
\tightlist
\item
  \textbf{Create a second model \texttt{model\_2} for the train data
  which includes \texttt{age} and \texttt{tax} as predictors. Calculate
  the train and validation MSE.}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lstat }\SpecialCharTok{+}\NormalTok{ age }\SpecialCharTok{+}\NormalTok{ tax, }\AttributeTok{data =}\NormalTok{ boston\_train)}


\NormalTok{y\_pred\_train\_2 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(model\_2, }\AttributeTok{newdata =}\NormalTok{ boston\_train)}

\CommentTok{\# Actual values from the training dataset}
\NormalTok{y\_true\_train\_2 }\OtherTok{\textless{}{-}}\NormalTok{ boston\_train}\SpecialCharTok{$}\NormalTok{medv}

\CommentTok{\# Calculate the Mean Square Error using the mse function for the training data}
\NormalTok{model\_2\_mse\_train }\OtherTok{\textless{}{-}} \FunctionTok{mse}\NormalTok{(y\_true\_train\_2, y\_pred\_train\_2)}

\FunctionTok{print}\NormalTok{(model\_2\_mse\_train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 38.23648
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred\_valid\_2 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(model\_2, }\AttributeTok{newdata =}\NormalTok{ boston\_test)}


\NormalTok{y\_true\_valid\_2 }\OtherTok{\textless{}{-}}\NormalTok{ boston\_test}\SpecialCharTok{$}\NormalTok{medv}

\CommentTok{\# Calculate the Mean Square Error using the mse function for the validation data}
\NormalTok{model\_2\_mse\_valid }\OtherTok{\textless{}{-}} \FunctionTok{mse}\NormalTok{(y\_true\_valid\_2, y\_pred\_valid\_2)}


\FunctionTok{print}\NormalTok{(model\_2\_mse\_valid)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 32.4873
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{15}
\tightlist
\item
  \textbf{Compare model 1 and model 2 in terms of their training and
  validation MSE. Which would you choose and why?}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Training MSE Comparison:}
\CommentTok{\#model\_1\_mse\_train vs. model\_2\_mse\_train: If model\_2\_mse\_train is lower than model\_1\_mse\_train, it suggests that model\_2, with the additional predictors (age and tax), fits the training data better. A lower training MSE indicates that the model captures more of the variance in the data due to more variables explaining the variability in medv.}

\CommentTok{\#Validation MSE Comparison:}
\CommentTok{\#model\_1\_mse\_valid vs. model\_2\_mse\_valid: This comparison is crucial because it evaluates how well each model generalizes to unseen data. If model\_2\_mse\_valid is significantly lower than model\_1\_mse\_valid, it suggests that the complexity added by including age and tax as predictors does not lead to overfitting and indeed helps in making more accurate predictions on new data.}
\end{Highlighting}
\end{Shaded}

In choosing the best model, you should base your answer on the
validation MSE. Using the out of sample mean square error, we have made
a model decision (which parameters to include, only \texttt{lstat}, or
using \texttt{age} and \texttt{tax} in addition to \texttt{lstat} to
predict housing value). Now we have selected a final model.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{16}
\tightlist
\item
  \textbf{For your final model, retrain the model one more time using
  both the training \emph{and} the validation set. Then, calculate the
  test MSE based on the (retrained) final model. What does this number
  tell you?}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{combined\_data }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(boston\_train, boston\_test)}

\NormalTok{final\_model }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lstat }\SpecialCharTok{+}\NormalTok{ age }\SpecialCharTok{+}\NormalTok{ tax, }\AttributeTok{data =}\NormalTok{ combined\_data)}

\CommentTok{\# Predict using the final model on the test dataset}
\NormalTok{y\_pred\_test }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(final\_model, }\AttributeTok{newdata =}\NormalTok{ boston\_test)}
\NormalTok{y\_true\_test }\OtherTok{\textless{}{-}}\NormalTok{ boston\_test}\SpecialCharTok{$}\NormalTok{medv}

\CommentTok{\# Calculate Mean Square Error on the test set}
\NormalTok{final\_model\_mse\_test }\OtherTok{\textless{}{-}} \FunctionTok{mse}\NormalTok{(y\_true\_test, y\_pred\_test)}
\FunctionTok{print}\NormalTok{(final\_model\_mse\_test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 31.98456
\end{verbatim}

As you will see during the remainder of the course, usually we set apart
the test set at the beginning and on the remaining data perform the
train-validation split multiple times. Performing the train-validation
split multiple times is what we for example do in cross validation (see
below). The validation sets are used for making model decisions, such as
selecting predictors or tuning model parameters, so building the model.
As the validation set is used to base model decisions on, we can not use
this set to obtain a true out-of-sample MSE. That's where the test set
comes in, it can be used to obtain the MSE of the final model that we
choose when all model decisions have been made. As all model decisions
have been made, we can use all data except for the test set to retrain
our model one last time using as much data as possible to estimate the
parameters for the final model.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{optional-cross-validation}{%
\section{Optional: cross-validation}\label{optional-cross-validation}}

This is an advanced exercise. Some components we have seen before in
this lab, but some things will be completely new. Try to complete it by
yourself, but don't worry if you get stuck. If you need to refresh your
memory on \texttt{for\ loops} in \texttt{R}, have another look at lab 1
on the course website.

Use help in this order:

\begin{itemize}
\tightlist
\item
  R help files
\item
  Internet search \& stack exchange
\item
  Your peers
\item
  The answer, which shows one solution
\end{itemize}

You may also just read the answer when they have been made available and
try to understand what happens in each step.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{17}
\tightlist
\item
  \textbf{Create a function that performs k-fold cross-validation for
  linear models.}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Inputs:

\begin{itemize}
\tightlist
\item
  \texttt{formula}: a formula just as in the \texttt{lm()} function
\item
  \texttt{dataset}: a data frame
\item
  \texttt{k}: the number of folds for cross validation
\item
  any other arguments you need necessary
\end{itemize}

Outputs:

\begin{itemize}
\tightlist
\item
  Mean square error averaged over folds
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{crossval }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(formula, dataset, k) \{}
  \FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)  }\CommentTok{\# For reproducibility}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(dataset)}
\NormalTok{  indices }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{k, n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  mse\_values }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(k)}
  
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{k) \{}
\NormalTok{    test\_idx }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(indices }\SpecialCharTok{==}\NormalTok{ i)}
\NormalTok{    train\_idx }\OtherTok{\textless{}{-}} \FunctionTok{setdiff}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{n, test\_idx)}
    
\NormalTok{    train\_data }\OtherTok{\textless{}{-}}\NormalTok{ dataset[train\_idx, ]}
\NormalTok{    test\_data }\OtherTok{\textless{}{-}}\NormalTok{ dataset[test\_idx, ]}
    
\NormalTok{    model }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(formula, }\AttributeTok{data =}\NormalTok{ train\_data)}
\NormalTok{    predictions }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(model, }\AttributeTok{newdata =}\NormalTok{ test\_data)}
\NormalTok{    mse\_values[i] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((test\_data}\SpecialCharTok{$}\NormalTok{medv }\SpecialCharTok{{-}}\NormalTok{ predictions)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{  \}}
  
  \FunctionTok{return}\NormalTok{(}\FunctionTok{mean}\NormalTok{(mse\_values))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{18}
\tightlist
\item
  \textbf{Use your function to perform 9-fold cross validation with a
  linear model with as its formula
  \texttt{medv\ \textasciitilde{}\ lstat\ +\ age\ +\ tax}. Compare it to
  a model with as formula
  \texttt{medv\ \textasciitilde{}\ lstat\ +\ I(lstat\^{}2)\ +\ age\ +\ tax}.}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataset }\OtherTok{\textless{}{-}}\NormalTok{ Boston  }\CommentTok{\# Assuming \textquotesingle{}Boston\textquotesingle{} is your dataset}
\NormalTok{k }\OtherTok{\textless{}{-}} \DecValTok{9}  \CommentTok{\# Number of folds}

\CommentTok{\# Linear model with lstat, age, and tax}
\NormalTok{mse1 }\OtherTok{\textless{}{-}} \FunctionTok{crossval}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lstat }\SpecialCharTok{+}\NormalTok{ age }\SpecialCharTok{+}\NormalTok{ tax, dataset, k)}

\CommentTok{\# Linear model with lstat, lstat\^{}2, age, and tax}
\NormalTok{mse2 }\OtherTok{\textless{}{-}} \FunctionTok{crossval}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lstat }\SpecialCharTok{+} \FunctionTok{I}\NormalTok{(lstat}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}\NormalTok{ age }\SpecialCharTok{+}\NormalTok{ tax, dataset, k)}

\CommentTok{\# Output the results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"MSE for model 1 (lstat + age + tax):"}\NormalTok{, mse1))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "MSE for model 1 (lstat + age + tax): 38.3364006538797"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"MSE for model 2 (lstat + I(lstat\^{}2) + age + tax):"}\NormalTok{, mse2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "MSE for model 2 (lstat + I(lstat^2) + age + tax): 28.3918356637821"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Comparing MSEs: The mean square errors (MSE) from the cross{-}validation results}
\CommentTok{\#can indicate which model performs better in terms of prediction accuracy.}
\CommentTok{\#The model with the lower MSE is considered to have a better fit because it means}
\CommentTok{\#less deviation between the predicted and actual values.}

\CommentTok{\# Model Complexity: The second model includes a quadratic term for lstat, which }
\CommentTok{\#might capture more complex relationships in the data but also risks overfitting.}
\end{Highlighting}
\end{Shaded}


\end{document}
